{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from huggingface_hub) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from huggingface_hub) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from packaging>=20.9->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from requests->huggingface_hub) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from requests->huggingface_hub) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from requests->huggingface_hub) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\gamer\\miniconda3\\envs\\jupyter\\lib\\site-packages (from tqdm->huggingface_hub) (0.4.4)\n",
      "Installing collected packages: filelock, huggingface_hub\n",
      "Successfully installed filelock-3.8.0 huggingface_hub-0.10.1\n"
     ]
    }
   ],
   "source": [
    "# requirements:\n",
    "! pip install huggingface_hub\n",
    "! git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cddd5c4dd5849b9b5c0b91937d08257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "#enter your API key, you can make one for free on HF\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceApi\n",
    "\n",
    "inference = InferenceApi(\"bigscience/bloom\",token=HfFolder.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt,\n",
    "          max_length = 32,\n",
    "          top_k = 0,\n",
    "          num_beams = 0,\n",
    "          no_repeat_ngram_size = 2,\n",
    "          top_p = 0.85,\n",
    "          seed=42,\n",
    "          temperature=0.7,\n",
    "          greedy_decoding = False,\n",
    "          return_full_text = False):\n",
    "    \n",
    "\n",
    "    top_k = None if top_k == 0 else top_k\n",
    "    do_sample = False if num_beams > 0 else not greedy_decoding\n",
    "    num_beams = None if (greedy_decoding or num_beams == 0) else num_beams\n",
    "    no_repeat_ngram_size = None if num_beams is None else no_repeat_ngram_size\n",
    "    top_p = None if num_beams else top_p\n",
    "    early_stopping = None if num_beams is None else num_beams > 0\n",
    "\n",
    "    params = {\n",
    "        \"max_new_tokens\": max_length,\n",
    "        \"top_k\": top_k,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature,\n",
    "        \"do_sample\": do_sample,\n",
    "        \"seed\": seed,\n",
    "        \"early_stopping\":early_stopping,\n",
    "        \"no_repeat_ngram_size\":no_repeat_ngram_size,\n",
    "        \"num_beams\":num_beams,\n",
    "        \"return_full_text\":return_full_text\n",
    "    }\n",
    "    \n",
    "    s = time.time()\n",
    "    response = inference(prompt, params=params)\n",
    "    #print(response)\n",
    "    proc_time = time.time()-s\n",
    "    #print(f\"Processing time was {proc_time} seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"※ Mojim.com \\n以下是周杰伦创作的歌词：\\n\" # Adding the Mojim characters to the data just extracts the lyrics from the model straight up\n",
    "# prompt = \"以下是周杰伦创作的歌词：\\n\"\n",
    "\n",
    "#TOP_P = [0.80, 0.85, 0.90, 0.95]\n",
    "TOP_P = 1.0\n",
    "NUM_SAMPLES = 3000\n",
    "MAX_LENGTH = 100\n",
    "TEMP = 1.0\n",
    "#prompt = \"歌词：\\n\"\n",
    "prompt = \"下面是一首歌的中文歌词。\\n歌词：\\n\"\n",
    "\n",
    "START_S = 0\n",
    "seeds = np.arange(START_S, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "with open(f\"bloom_log_{TOP_P}.txt\", \"a\") as f:\n",
    "    for s in seeds:\n",
    "        success = False\n",
    "\n",
    "        while not success:\n",
    "            resp = infer(prompt, seed=int(s), max_length=MAX_LENGTH, top_p=TOP_P, temperature=TEMP)\n",
    "            record = {\"response\":resp, \"seed\":int(s), \"top_p\":TOP_P, \"max_length\":MAX_LENGTH, \"temperature\":TEMP}\n",
    "            print(json.dumps(record), file=f)\n",
    "\n",
    "            try:\n",
    "                a = resp[0]\n",
    "                success = True\n",
    "            except KeyError:\n",
    "                print(\"Received error... waiting 15 seconds.\", file=f)\n",
    "                success = False\n",
    "                time.sleep(15)\n",
    "\n",
    "        samples.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samples:\n",
    "    print(\"=====\")\n",
    "    print(s[\"response\"][0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说真的,你比从前快乐,那祝福的话叫我如何能够说的出口,过往的欢乐是否褪色想问你怎么舍得不要在耳边再说你会想我,如果我真的会难过,不是说好要一起到老,怎么会剩我一个人,度过风雨的时分,也许时间是一种解药,也是我现在正服下的毒药,说好要一起到老,怎么剩我一个人,度过风雨的时分,爱情给的苦药,我"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是周杰伦创作的歌词：\n",
    "# 我听到传来的谁的声音\n",
    "# 象那梦里呜咽中的小河\n",
    "# 我看到远去的谁的步伐\n",
    "# 遮住告别时哀伤的眼神\n",
    "# 不明白的是为何你情愿\n",
    "# 让风尘刻画你的样子\n",
    "# 就像早已忘情的世界\n",
    "# 曾经拥有你的名字我的声音\n",
    "# 那悲歌总会在梦中清醒\n",
    "# 诉说一点哀伤过的往事\n",
    "# 那看似满不在乎转过身的\n",
    "# 是风干泪眼后萧瑟的影子\n",
    "# 不明白的是为何"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one looks like it was straight up lifted from Mojim.  NLM plagiarism is a problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是周杰伦创作的歌词：\n",
    "# 《七里香》\n",
    "# 作曲：周杰伦\n",
    "# 作词：方文山\n",
    "# 窗外的麻雀 在电线杆上多嘴\n",
    "# 你说这一句 很有夏天的感觉\n",
    "# 手中的铅笔 在纸上来来回回\n",
    "# 我用几行字形容你是我的谁\n",
    "# 秋刀鱼的滋味 猫跟你都想了解\n",
    "# 初恋的香味就这样被我们寻回\n",
    "# 那温暖的阳光 像刚摘的鲜艳草莓\n",
    "# 你说你舍不得吃掉这一种感觉\n",
    "# 雨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics on generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "p080 = pd.read_json(\"./BLOOM/3K_BLOOM_p080.jsonl\", lines=True)\n",
    "p085 = pd.read_json(\"./BLOOM/3K_BLOOM_p085.jsonl\", lines=True)\n",
    "p090 = pd.read_json(\"./BLOOM/3K_BLOOM_p090.jsonl\", lines=True)\n",
    "p095 = pd.read_json(\"./BLOOM/3K_BLOOM_p095.jsonl\", lines=True)\n",
    "p099 = pd.read_json(\"./BLOOM/3K_BLOOM_p099.jsonl\", lines=True)\n",
    "rt = pd.read_json(\"./BLOOM/top_song_lyrics_cleaned_cn.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "p080_text = p080[\"response\"].apply(lambda a: a[0][\"generated_text\"]).str.split(\"下面是一首歌的中文歌词。\\n歌词：\\n\").apply(lambda a: a[1])\n",
    "p085_text = p085[\"response\"].apply(lambda a: a[0][\"generated_text\"]).str.split(\"下面是一首歌的中文歌词。\\n歌词：\\n\").apply(lambda a: a[1])\n",
    "p090_text = p090[\"response\"].apply(lambda a: a[0][\"generated_text\"]).str.split(\"下面是一首歌的中文歌词。\\n歌词：\\n\").apply(lambda a: a[1])\n",
    "p095_text = p095[\"response\"].apply(lambda a: a[0][\"generated_text\"]).str.split(\"下面是一首歌的中文歌词。\\n歌词：\\n\").apply(lambda a: a[1])\n",
    "p099_text = p099[\"response\"].apply(lambda a: a[0][\"generated_text\"]).str.split(\"下面是一首歌的中文歌词。\\n歌词：\\n\").apply(lambda a: a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_text = pd.Series([a[:100] for a in rt[\"cleaned_lyrics\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simplified from:\n",
    "References: https://github.com/wangpf3/imagine-and-verbalize/blob/main/verbalization_learning/lib/utils/text_evaluation.py\n",
    "https://github.com/VegB/iNLG/blob/main/code/text_evaluation.py\n",
    "\"\"\"\n",
    "\n",
    "def evaluator(gts, res):\n",
    "    eval = {}\n",
    "    # =================================================\n",
    "    # Compute scores\n",
    "    # =================================================\n",
    "    for scorer, method in scorers:\n",
    "        score, scores = scorer.compute_score(gts, res)\n",
    "        if type(method) == list:\n",
    "            for sc, scs, m in zip(score, scores, method):\n",
    "                eval[m] = sc\n",
    "        else:\n",
    "            eval[method] = score\n",
    "    return eval\n",
    "\n",
    "def evaluate_sentence(gen_path, ref_path):\n",
    "    gts = {}\n",
    "    res = {}\n",
    "    with open(ref_path, 'r') as f:\n",
    "        gts_lines = f.readlines()\n",
    "    with open(gen_path, 'r') as f:\n",
    "        res_lines = f.readlines()\n",
    "\n",
    "    for gts_line, res_line in zip(gts_lines, res_lines):\n",
    "        sample = json.loads(gts_line.strip())\n",
    "        generation = json.loads(res_line.strip())\n",
    "        key = '#'.join(sorted(sample['entities']))\n",
    "        if key not in gts:\n",
    "            gts[key] = []\n",
    "            gts[key].append(sample['text'])\n",
    "            res[key] = []\n",
    "            res[key].append(generation['text'])\n",
    "        else:\n",
    "            gts[key].append(sample['text'])\n",
    "    return evaluator(gts, res)\n",
    "\n",
    "def evaluate_story(gen_path, ref_path):\n",
    "    gts = {}\n",
    "    res = {}\n",
    "    with open(ref_path, 'r') as f:\n",
    "        gts_lines = f.readlines()\n",
    "    with open(gen_path, 'r') as f:\n",
    "        res_lines = f.readlines()\n",
    "\n",
    "    for gts_line, res_line in zip(gts_lines, res_lines):\n",
    "        sample = json.loads(gts_line.strip())\n",
    "        generation = json.loads(res_line.strip())\n",
    "        key = sample['id']\n",
    "        gts[key] = []\n",
    "        gts[key].append(sample['text'])\n",
    "        res[key] = []\n",
    "        res[key].append(generation['text'])\n",
    "    return evaluator(gts, res)\n",
    "\n",
    "\n",
    "def parse_text_to_tokens(sentence):\n",
    "    return [t.text for t in nlp(sentence)]\n",
    "\n",
    "def compute_recall(concepts, prediction, verbose=False):\n",
    "    concept_token_list = parse_text_to_tokens(concepts)\n",
    "    cnt = 0.\n",
    "    for t in concept_token_list:\n",
    "        if prediction.find(t) != -1:\n",
    "            cnt += 1\n",
    "\n",
    "    recall = cnt / len(concept_token_list)\n",
    "    if verbose:\n",
    "        print(f'concepts:\\t{concepts}\\nprediction:\\t{prediction}\\n'\n",
    "            f'recall rate = {recall*100:.2f} %')\n",
    "    return recall\n",
    "\n",
    "def avg_list(lst):\n",
    "    if not lst:\n",
    "        return 0\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def compute_concept_recall(concept_list, pred_list):\n",
    "    recall_list = []\n",
    "    for concepts, prediction in zip(concept_list, pred_list):\n",
    "        recall_list.append(compute_recall(concepts, prediction))\n",
    "    recall_rate = avg_list(recall_list)\n",
    "    return recall_rate\n",
    "\n",
    "\n",
    "def ngram_precook(s, n=4, verbose=False):\n",
    "    words = s.split()\n",
    "    repeat_index = defaultdict(int)\n",
    "    for k in range(1,n+1):  # k gram\n",
    "        all_k_gram_list = []\n",
    "        for i in range(len(words)-k+1):  # start index\n",
    "            ngram = tuple(words[i:i+k])\n",
    "            all_k_gram_list.append(ngram)\n",
    "        num_unique_k_gram = len(set(all_k_gram_list))\n",
    "        if len(all_k_gram_list):\n",
    "            repeat_index[k] = float(num_unique_k_gram) / len(all_k_gram_list)\n",
    "        else:  # no k-gram\n",
    "            repeat_index[k] = 1e-13\n",
    "        if verbose:\n",
    "            print(f'{k}-gram:\\tindex:\\t{repeat_index[k]:.2f}\\tall:\\t{len(all_k_gram_list)}\\tunique:{num_unique_k_gram}')\n",
    "    return repeat_index\n",
    "\n",
    "\n",
    "def compute_repetition(text_list, n=4, verbose=False):\n",
    "    \"\"\"\n",
    "    See https://arxiv.org/pdf/2202.06417.pdf Section 4.1.2\n",
    "    \"\"\"\n",
    "    repetition_list = defaultdict(list)\n",
    "    for text in text_list:\n",
    "        repeat_score = ngram_precook(text, n=n, verbose=verbose)\n",
    "        for k in range(1, n+1):\n",
    "            repetition_list[k].append(repeat_score[k])\n",
    "    repetition_scores = {k: 1 - np.mean(repetition_list[k]) for k in range(1, n+1)}\n",
    "    if verbose:\n",
    "        for k in range(1, n+1):\n",
    "            print(f'rep-{k}:\\t{repetition_scores[k]}\\t{repetition_list[k]}\\tmean:({np.mean(repetition_list[k])})')\n",
    "    return repetition_scores\n",
    "\n",
    "\n",
    "def compute_diversity(repetition_scores):\n",
    "    \"\"\"\n",
    "    See https://arxiv.org/pdf/2202.06417.pdf Section 4.1.2\n",
    "    \"\"\"\n",
    "    diversity = 1.\n",
    "    for k in range(2, 5):\n",
    "        diversity *= (1-repetition_scores[k])\n",
    "    return diversity\n",
    "\n",
    "\n",
    "def distinct_n_sentence_level(sentence, n):\n",
    "    \"\"\"\n",
    "    Compute distinct-N for a single sentence.\n",
    "    :param sentence: a list of words.\n",
    "    :param n: int, ngram.\n",
    "    :return: float, the metric value.\n",
    "    \"\"\"\n",
    "    if len(sentence) == 0:\n",
    "        return 0.0  # Prevent a zero division\n",
    "    distinct_ngrams = set(nltk.ngrams(sentence, n))\n",
    "    return len(distinct_ngrams) / len(sentence)\n",
    "\n",
    "\n",
    "def distinct_n_corpus_level(sentences, n):\n",
    "    \"\"\"\n",
    "    Compute average distinct-N of a list of sentences (the corpus).\n",
    "    :param sentences: a list of sentence.\n",
    "    :param n: int, ngram.\n",
    "    :return: float, the average value.\n",
    "    \"\"\"\n",
    "    return sum(distinct_n_sentence_level(sentence, n) for sentence in sentences) / len(sentences)\n",
    "\n",
    "\n",
    "def compute_distinct_n(text_list, n=2):\n",
    "    distinct_n = {}\n",
    "    for i in range(1, n+1):\n",
    "        d = distinct_n_corpus_level(sentences=text_list, n=i)\n",
    "        distinct_n[i] = d\n",
    "    return distinct_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_text_list(text_list):\n",
    "    metrics = {}\n",
    "    repetition_scores = compute_repetition(text_list=text_list)\n",
    "    for k, s in repetition_scores.items():\n",
    "        metrics[f'rep-{k}'] = s\n",
    "\n",
    "    diversity_scores = compute_diversity(repetition_scores)\n",
    "    metrics['diversity'] = diversity_scores\n",
    "\n",
    "    distinct_scores = compute_distinct_n(text_list=text_list)\n",
    "    for k in range(1, 3):\n",
    "        metrics[f'distinct-{k}'] = distinct_scores[k]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P0.80\n",
      "P0.85\n",
      "P0.90\n",
      "P0.95\n",
      "P0.99\n",
      "Human\n",
      "CPU times: total: 4.05 s\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"P0.80\")\n",
    "p080_result = eval_text_list(p080_text)\n",
    "print(\"P0.85\")\n",
    "p085_result = eval_text_list(p085_text)\n",
    "print(\"P0.90\")\n",
    "p090_result = eval_text_list(p090_text)\n",
    "print(\"P0.95\")\n",
    "p095_result = eval_text_list(p095_text)\n",
    "print(\"P0.99\")\n",
    "p099_result = eval_text_list(p099_text)\n",
    "print(\"Human\")\n",
    "human_result = eval_text_list(real_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = {\n",
    "    \"p080\":p080_result,\n",
    "    \"p085\":p085_result,\n",
    "    \"p090\":p090_result,\n",
    "    \"p095\":p095_result,\n",
    "    \"p099\":p099_result,\n",
    "    \"human\":human_result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  rep-2 &  rep-3 &  rep-4 &  diversity &  distinct-2 \\\\\n",
      "\\midrule\n",
      "p080  &  0.120 &  0.090 &  0.072 &      0.743 &       0.650 \\\\\n",
      "p085  &  0.095 &  0.073 &  0.063 &      0.786 &       0.689 \\\\\n",
      "p090  &  0.072 &  0.055 &  0.047 &      0.835 &       0.722 \\\\\n",
      "p095  &  0.054 &  0.044 &  0.039 &      0.868 &       0.760 \\\\\n",
      "p099  &  0.040 &  0.034 &  0.032 &      0.897 &       0.783 \\\\\n",
      "human &  0.021 &  0.013 &  0.012 &      0.954 &       0.870 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_25780\\1624173298.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(pd.DataFrame(combined).T.drop(columns=[\"rep-1\", \"distinct-1\"]).round(3).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(combined).T.drop(columns=[\"rep-1\", \"distinct-1\"]).round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
